---
- name: get cpu
  tags: [configure_map_reduce, upgrade, scale]
  command: "nproc --all"
  register: node_cpu
  changed_when: false
- name: get host available memory
  tags: [upgrade, configure_yarn, scale]
  shell: "cat /proc/meminfo | grep MemTotal | awk '{print int($2/1024)}'"
  register: out
  changed_when: false
- name: get available memory
  set_fact:
    available_memory_mb: "{{ out.stdout }}"
  tags: [upgrade, configure_yarn, scale]
- name: get available memory for yarn node manager
  set_fact:
    yarn_nodemanager_memory_mb: "{{ (available_memory_mb | int - 800 )| int }}"
  tags: [upgrade, configure_yarn, scale]
- name: crypted disk is running
  tags: [check_hosts, upgrade]
  shell: "if mountpoint -q /{{ crypted_disk }}; then echo 'MOUNTED'; else echo 'NOT-MOUNTED'; fi"
  register: mount_output
  changed_when: false
- name: start crypted disk
  tags: [check_hosts, upgrade]
  shell: |
    echo -n "{{ decrypt_disk_pass }}" | cryptsetup luksOpen --key-file=- /dev/{{ inventory_hostname.split('.')[0] }}-crypt-1/{{ crypted_disk  }} {{ crypted_disk  }}
  args:
    executable: /bin/bash
  register: out
  changed_when: out.stdout=='' and out.stderr==''
  failed_when: out.stderr != '' and not out.stderr.endswith('already exists.')
  when: mount_output.stdout == 'NOT-MOUNTED'
- name: mount crypted disk 
  tags: [check_hosts, upgrade]
  shell: "mount /{{ crypted_disk  }}"
  register: out
  changed_when: true 
  when: mount_output.stdout == 'NOT-MOUNTED'
- name: IPv6 disables
  tags: [check_hosts, upgrade]
  lineinfile:
    path: "/etc/sysctl.conf" 
    regexp: '^net.ipv6.conf.all.disable_ipv6'
    line: "net.ipv6.conf.all.disable_ipv6 = 1"
  notify: apply_sysctl    
- name: get ip to use
  shell: "ip addr list | grep \"{{ front_network  }}\\|{{ back_network  }}\" | grep \"inet \" | awk {'print $2'} | awk -F \"/\" {'print $1'}" 
  register: app_ip
  changed_when: false
  tags: [etc_hosts, upgrade]
- set_fact:
    app_ip: "{{ app_ip.stdout }}"
  tags: [etc_hosts, upgrade]
- name: set ips alias on /etc/hosts
  blockinfile:
    path: /etc/hosts
    block: |
      {{hostvars[item].app_ip}} {{ item.split('.')[0] }}-{{ hadoop_cluster_name }}
    marker: "# {mark} Managed ip for {{ item }} alias do not edit!" 
  with_items : "{{ ansible_play_hosts }}"
  tags: [etc_hosts, upgrade]
- name: set ips alias on /etc/hosts for internal custom serviecs
  blockinfile:
    path: /etc/hosts
    block: |
      {{item.ip}} {{ item.name }}
    marker: "# {mark} Managed ip for {{ item.name }} alias do not edit!" 
  with_items : "{{ demy_custom_hosts }}"
  tags: [etc_hosts, upgrade]
- name: installation folder
  file:
    path: "{{ hadoop_install }}"
    state: directory
    mode: 0751
    owner: hadoop
    group: hadoop
  tags: upgrade
- name: custom tmp folder present
  file:
    path: "{{ tmp_dir }}"
    state: directory
    mode: u=rwx,g=rwx,o=rwx,g+s
    owner: root
    group: root
  tags: [upgrade, tmp]
- name: custom libs folder exists
  file:
    path: "{{ custom_libs }}"
    state: directory
    mode: 0771
    owner: hadoop
    group: hadoop
  tags: [upgrade, packages, python]
- name: backports are activated
  apt_repository:
    repo: "deb http://ftp.fr.debian.org/debian {{ ansible_distribution_release }}-backports main"
  tags: upgrade
- name: install backports packages
  tags: [packages, upgrade]
  apt:
    name: "{{ item }}"
    default_release: "{{ ansible_distribution_release }}-backports"
    update_cache: true
    state: latest
  with_items: ["{{ java_package }}", "{{ java_package_spark }}", maven, r-base  ]
  notify: [set_java_default, set_java_for_R]
- name: set java home
  tags: [java, upgrade]
  lineinfile:
    path: "/etc/environment" 
    regexp: '^JAVA_HOME='
    line: "JAVA_HOME={{ java_home }}"
  notify: set_java_default
- name: Getting key for installing llvm
  tags: [packages, upgrade, python]
  apt_key:
    data: "{{ lookup('url', 'https://apt.llvm.org/llvm-snapshot.gpg.key', split_lines=False) }}" 
    state: present
  environment:
    HTTPS_PROXY: "http://{{ proxy_host }}:{{ proxy_port }}"
    HTTP_PROXY: "http://{{ proxy_host }}:{{ proxy_port }}"
- name: Ensuring a fresh version llvm is present
  tags: [packages, upgrade, python]
  apt_repository:
    repo: "deb http://apt.llvm.org/{{ ansible_distribution_release }}/ llvm-toolchain-{{ ansible_distribution_release }}-6.0 main"
    state: present
- name: get node version
  tags: [packages, upgrade, test]
  shell: "if [ -f /usr/bin/nodejs  ]; then if [ `/usr/bin/nodejs --version` == 'v10.12.0' ]; then echo 'OK'; else echo 'UPDATE'; fi; else echo 'UPDATE'; fi"
  register: updatenode
  changed_when: false
- name: install node if necessary
  tags: [packages, upgrade, test]
  shell: | 
    export http_proxy=http://{{ proxy_host }}:{{ proxy_port }}
    export https_proxy=http://{{ proxy_host }}:{{ proxy_port }}
    curl -sL https://deb.nodesource.com/setup_10.x | bash -
    apt-get install -y nodejs
  register: updatenode
  changed_when: true
  when: updatenode.stdout == 'UPDATE'
  notify: [ set_npm_proxy ]
- name: installing packages
  tags: [packages, upgrade]
  apt:
    name: "{{ item }}"
    update_cache: true
    state: latest
  with_items: [build-essential, g++, autoconf, automake, libtool, zlib1g-dev, pkg-config, libssl-dev, xmlstarlet, git, libfontconfig ,pandoc, proj-data, locales, curl, jq ]
  notify: [ set_cran_mirror ]
- name: installing backportes packages
  tags: [packages, upgrade, python]
  apt:
    name: "{{ item }}"
    default_release: "{{ ansible_distribution_release }}-backports"
    update_cache: true
    state: latest
  with_items: [python-setuptools, libgdal-dev, libgeos-dev, libproj-dev, cmake, llvm-6.0, libbz2-dev, libreadline-gplv2-dev, libsqlite3-dev, libncurses5-dev, libncursesw5-dev, xz-utils,tk-dev, libgdbm-dev, libc6-dev, libssl-dev ] #, python3, python3-pip, python3-numpy, python3-scipy]
  notify: [ set_npm_proxy, set_cran_mirror ]
- name: download python
  tags: [python, upgrade]
  command: "wget https://www.python.org/ftp/python/{{ python_ver  }}/Python-{{ python_ver  }}.tgz"
  args:
    chdir: "{{ custom_libs }}"
    creates: "{{ custom_libs }}/Python-{{ python_ver }}.tgz"
  become_user: spark
- name: uncompress python
  tags: [python, upgrade]
  unarchive:
    src: "{{ custom_libs }}/Python-{{ python_ver }}.tgz"
    dest: "{{ custom_libs }}"
    remote_src: true 
  become_user: spark
- name: building python
  tags: [packages, upgrade, python]
  shell: |
   ./configure --enable-optimizations --with-ensurepip=install --prefix {{ custom_libs }}/python-{{ python_ver }}-lib --cache-file {{ tmp_dir }}/python-build
   make -j4
   make install
  args:
    chdir: "{{ custom_libs }}/Python-{{ python_ver }}"
    creates: "{{ custom_libs }}/python-{{ python_ver }}-lib"
  become_user: spark
  environment:
    TMPDIR: "{{ tmp_dir }}"
- name: create link to current python version
  tags: [python, upgrade]
  file:
    src: "{{ custom_libs }}/python-{{ python_ver }}-lib" 
    dest: "{{ python_home }}"
    owner: spark
    group: hadoop
    mode: 0751
    state: link
    #force: true
- name: upgrade pip
  tags: [packages, upgrade, python]
  pip:
    name: pip
    state: latest
    executable: "{{ pip }}"
  environment:
    TMPDIR: "{{ tmp_dir }}"
    HTTPS_PROXY: "http://{{ proxy_host }}:{{ proxy_port }}"
    HTTP_PROXY: "http://{{ proxy_host }}:{{ proxy_port }}"
    LLVM_CONFIG: "/usr/lib/llvm-6.0/bin/llvm-config"
- name: update requirement files
  tags: [packages, upgrade, python]
  copy:
    dest: "{{ custom_libs }}/pip_requirements"
    content: |
      git+https://github.com/gutfeeling/word_forms.git#egg=word_forms
      pandas
      scikit-learn
      nltk
      contractions
      inflect
      pprint
      gensim
      datetime
      python-dateutil
      pyarrow
- name: install python packages
  tags: [packages, upgrade, python]
  pip:
    requirements: "{{ custom_libs }}/pip_requirements"
    executable: "{{ pip }}"
  environment:
    TMPDIR: "{{ tmp_dir }}"
    HTTPS_PROXY: "http://{{ proxy_host }}:{{ proxy_port }}"
    HTTP_PROXY: "http://{{ proxy_host }}:{{ proxy_port }}"
    LLVM_CONFIG: "/usr/lib/llvm-6.0/bin/llvm-config"
- name: install R packages for Spark
  tags: [packages, upgrade, r_packages]
  shell: |
    export http_proxy=http://{{ proxy_host }}:{{ proxy_port }}
    export https_proxy=http://{{ proxy_host }}:{{ proxy_port }}
    export ftp_proxy={{ proxy_host }}:{{ proxy_port }}
    R -e "list.of.packages <- c(\"{{ spark_r_packages_url_name | join('\", \"') }}\");list.of.urls <- c(\"{{ spark_r_packages_url | join('\", \"') }}\");map <- new.env(hash=T, parent=emptyenv());for(i in 1:length(list.of.packages)) {map[[list.of.packages[i]]]<-list.of.urls[i]};new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])]; if(length(new.packages)) install.packages(lapply(new.packages, function(x) map[[x]]), repos=NULL, type='source')"
    R -e "list.of.packages <- c(\"{{ spark_r_packages | join('\", \"') }}\"); new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,\"Package\"])]; if(length(new.packages)) install.packages(new.packages, repos=c('https://cran.univ-paris1.fr','https://ftp.igh.cnrs.fr/pub/CRAN/','http://cran.irsn.fr/'))"
  register: out
  failed_when: (out.stderr | regex_search('(^|[\\n])(ERROR|WARNING)')|string) in 'ERROR,WARNING,\nERROR,\nWARNING'
  changed_when: out.stderr|length > 0
  notify: restart zeppelin
- name: downloading github libraries
  tags: [packages, upgrade, python]
  git:
    repo: "{{ item.repo }}"
    dest: "{{ custom_libs }}/{{ item.name }}" 
    version: "{{ item.version }}"
  with_items:
  - {name: "WDDS", repo: "https://github.com/WDDS/Tweet-Classification-Diabetes-Distress.git", version: "devAA" }
  environment:
    TMPDIR: "{{ tmp_dir }}"
    HTTPS_PROXY: "http://{{ proxy_host }}:{{ proxy_port }}"
    HTTP_PROXY: "http://{{ proxy_host }}:{{ proxy_port }}"
  become_user: hadoop
- name: download google protocol buffer
  command: "wget -nc https://github.com/google/protobuf/releases/download/v{{ protobuf_ver }}/protobuf-{{ protobuf_ver }}.tar.gz"
  args:
    chdir: "{{ hadoop_install }}"
    creates: "{{ hadoop_install }}/protobuf-{{ protobuf_ver }}.tar.gz"
  tags: [protobuf, upgrade]
- name: uncompress protocol buffers 
  unarchive:
    src: "{{ hadoop_install }}/protobuf-{{ protobuf_ver }}.tar.gz"
    dest: "/usr/local/src"
    remote_src: true 
    creates: "/usr/local/src/protobuf-{{ protobuf_ver }}" 
  tags: [protobuf, upgrade]
- name: make/install protocol buffers
  command: "{{ item }}"
  args:
    chdir: "/usr/local/src/protobuf-{{ protobuf_ver }}"
    creates: /usr/bin/protoc
  with_items:
  - ./autogen.sh
  - ./configure --prefix=/usr
  - make
  - make install
  tags: [protobuf, upgrade]
- name: install protocols buffers for java
  command: "mvn install -Dhttp.proxyHost={{ proxy_host }} -Dhttp.proxyPort={{ proxy_port }} -Dhttps.proxyHost={{ proxy_host }} -Dhttps.proxyPort={{ proxy_port }}"
  args:
    chdir: "/usr/local/src/protobuf-{{ protobuf_ver }}/java"
    creates: "/usr/local/src/protobuf-{{ protobuf_ver }}/java/target/protobuf-java-{{ protobuf_ver }}.jar"
  tags: [protobuf, upgrade]
- meta: flush_handlers
- name: download hadoop if does not exists
  tags: [install_hadoop, upgrade]
  command: "wget {{ apache_mirror }}/pub/apache/hadoop/common/hadoop-{{ hadoop_ver }}/hadoop-{{ hadoop_ver }}-src.tar.gz"
  args:
    chdir: "{{ hadoop_install }}"
    creates: "{{ hadoop_install }}/hadoop-{{ hadoop_ver }}-src.tar.gz"
- name: uncompress hadoop
  tags: [install_hadoop, upgrade]
  unarchive:
    src: "{{ hadoop_install }}/hadoop-{{ hadoop_ver }}-src.tar.gz"
    dest: "{{ hadoop_install }}"
    remote_src: true 
- name: Compile hadoop
  tags: [install_hadoop, upgrade]
  become_user: hadoop
  shell: |
          export JAVA_HOME={{ java_home }}
          mvn package -Pdist,native -DskipTests -Dtar -Dhttp.proxyHost={{ proxy_host }} -Dhttp.proxyPort={{ proxy_port }} -Dhttps.proxyHost={{ proxy_host }} -Dhttps.proxyPort={{ proxy_port }}
  args:
    chdir: "{{ hadoop_install }}/hadoop-{{ hadoop_ver }}-src"
    #creates: "{{ hadoop_install }}/hadoop-{{ hadoop_ver }}-src/hadoop-dist/target/hadoop-dist-{{ hadoop_ver }}.jar"
    creates: "{{ hadoop_install }}/hadoop-{{ hadoop_ver }}-src/hadoop-dist/target/hadoop-{{ hadoop_ver }}/share/hadoop/hdfs/hadoop-hdfs-{{ hadoop_ver }}.jar"
- name: copy compiled version (no overwrite)
  tags: [install_hadoop, upgrade]
  shell: "cp -R -v -n {{ hadoop_install }}/hadoop-{{ hadoop_ver }}-src/hadoop-dist/target/hadoop-{{ hadoop_ver }} {{ hadoop_install }}/ | wc -l"
  register: out
  changed_when: out.stdout!='0'
- name: create link to current version
  tags: [install_hadoop, upgrade]
  file:
    src: "{{ hadoop_install }}/hadoop-{{ hadoop_ver }}" 
    dest: "{{ hadoop_home }}"
    owner: hadoop
    group: hadoop
    mode: 0751
    state: link
    #force: true
- name: set hadoop home
  tags: [configure_hadoop, upgrade]
  lineinfile:
    path: "/etc/environment" 
    regexp: '^HADOOP_PREFIX='
    line: "HADOOP_PREFIX={{ hadoop_home  }}"
- name: ensure conf directory exists
  tags: [configure_hadoop, upgrade]
  file:
    path: "{{ item }}"
    state: directory
    mode: 0750
    owner: hadoop
    group: hadoop
  with_items:
  - "{{ hadoop_conf_dir }}"
- name: ensure log et pid folder exists
  tags: [configure_hadoop, upgrade]
  file:
    path: "{{ item }}"
    state: directory
    mode: 0770
    owner: hadoop
    group: hadoop
  with_items:
  - "{{ hadoop_log_dir }}"
  - "{{ hadoop_pid_dir }}"
- name: copy conf files (no overwrite)
  tags: [configure_hadoop, upgrade]
  shell: "cp -R -v -n {{ hadoop_home}}/etc/hadoop/* {{ hadoop_conf_dir }} | wc -l"
  register: out
  changed_when: out.stdout!='0'
- name: update hadoop-env.sh
  tags: [configure_hadoop, upgrade]
  lineinfile:
    path: "{{ hadoop_conf_dir }}/hadoop-env.sh" 
    regexp: "^export {{ item.var  }}"
    line: "export {{ item.var }}=\"{{ item.value }}\""
  with_items:
  - {var: "JAVA_HOME", value: "{{ java_home  }}" }
  - {var: "HADOOP_LOG_DIR", value: "{{ hadoop_log_dir }}" }
  - {var: "HADOOP_CONF_DIR", value: "{{ hadoop_conf_dir  }}" }
  - {var: "HADOOP_PID_DIR", value: "{{ hadoop_pid_dir  }}" }
  - {var: "HADOOP_NAMENODE_OPTS", value: "-Xmx{{ hdfs_namenode_daemon_memory_mb }}m" }
  - {var: "HADOOP_DATANODE_OPTS", value: "-Xmx{{ hdfs_datanode_daemon_memory_mb }}m" }
  - {var: "YARN_RESOURCEMANAGER_OPTS", value: "-Xmx{{ yarn_resourcemanager_daemon_memory_mb }}m" }
  - {var: "YARN_NODEMANAGER_OPTS", value: "-Xmx{{ yarn_nodemanager_daemon_memory_mb }}m" }
  - {var: "YARN_PROXYSERVER_OPTS", value: "-Xmx{{ yarn_webproxy_daemon_memory_mb  }}m" }
  - {var: "HADOOP_JOB_HISTORYSERVER_OPTS", value: "-Xmx{{ mapreduce_jobhistory_memory_mb }}m" }
  notify: [restart hdfs, restart yarn]
- name: copy script to update hadoop xml files
  tags: [configure_hadoop, upgrade, copy_xml, scale, configure_yarn, configure_map_reduce, upgrade, install_zeppelin, install_spark, configure_spark]
  copy:
    src: "./xmlpresent.sh"
    dest: "/tmp/xmlpresent.sh"
    owner: hadoop
    group: hadoop
    mode: 0770
- name: update core-site.xml
  tags: [configure_hadoop, upgrade]
  command: "/tmp/xmlpresent.sh --container-xpath \"/configuration\" --node \"property\" --property-node name --property-text \"{{ item.var  }}\" --value-node value --value \"{{ item.value  }}\" --file {{ hadoop_conf_dir }}/core-site.xml"
  register: out
  changed_when: not out.stdout.startswith('NO-CHANGE')
  with_items:
  - {var: "fs.defaultFS", value: "hdfs://{{ groups['namenode'][0].split('.')[0] }}-{{ hadoop_cluster_name }}:{{ hdfs_port }}" }
  - {var: "io.file.buffer.size", value: "{{ hdfs_file_buffer_bytes }}" }
  - {var: "hadoop.proxyuser.root.hosts", value: "{{ groups['hdfs_edge'][0].split('.')[0] }}-{{ hadoop_cluster_name }}" }
  - {var: "hadoop.proxyuser.root.groups", value: "*" }
  - {var: "hadoop.proxyuser.Spark.hosts", value: "{{ groups['hdfs_edge'][0].split('.')[0] }}-{{ hadoop_cluster_name }}" }
  - {var: "hadoop.proxyuser.spark.groups", value: "*" }
  notify: [restart hdfs, restart yarn]
- name: yarn log folder exist 
  tags: [configure_yarn, upgrade]
  file:  
    path: "{{ yarn_log_dir }}"
    state: directory
    mode: 0751
    owner: yarn
    group: hadoop
- name: setting necessary environment variable
  tags: [configure_yarn, upgrade]
  lineinfile:
    path: "{{ hadoop_conf_dir }}/yarn-env.sh" 
    regexp: "^export {{ item.var  }}"
    line: "export {{ item.var }}={{ item.value }}"
  with_items:
  - {var: "YARN_LOG_DIR", value: "{{ yarn_log_dir }}"} 
  - {var: "YARN_PID_DIR", value: "{{ hadoop_pid_dir  }}"}
  notify: restart yarn
- name: update yarn-site.xml for resouerce manager
  tags: [configure_yarn, upgrade, scale]
  command: "/tmp/xmlpresent.sh --container-xpath \"/configuration\" --node \"property\" --property-node name --property-text \"{{ item.var  }}\" --value-node value --value \"{{ item.value  }}\" --file {{ hadoop_conf_dir }}/yarn-site.xml"
  register: out
  changed_when: not out.stdout.startswith('NO-CHANGE')
  with_items:
  - {var: "yarn.acl.enable", value: "{{ yarn_acl  }}" }
  - {var: "yarn.admin.acl", value: "{{ yarn_admin_acl  }}" }
  - {var: "yarn.log-aggregation-enable", value: "{{ yarn_log_aggregation }}" }
  - {var: "yarn.resourcemanager.address", value: "{{ groups['resourcemanager'][0].split('.')[0] }}-{{ hadoop_cluster_name }}:{{ yarn_resourcemanager_port }}" }
  - {var: "yarn.resourcemanager.scheduler.address", value: "{{ groups['resourcemanager'][0].split('.')[0]  }}-{{ hadoop_cluster_name }}:{{ yarn_resourcescheduler_port  }}" }
  - {var: "yarn.resourcemanager.resource-tracker.address", value: "{{ groups['resourcemanager'][0].split('.')[0]  }}-{{ hadoop_cluster_name }}:{{ yarn_resourcetracker_port }}" }
  - {var: "yarn.resourcemanager.admin.address", value: "{{ groups['resourcemanager'][0].split('.')[0]  }}-{{ hadoop_cluster_name }}:{{ yarn_admin_port  }}" }
  - {var: "yarn.resourcemanager.webapp.address", value: "{{ groups['resourcemanager'][0].split('.')[0]  }}-{{ hadoop_cluster_name }}:{{ yarn_webapp_port }}" }
  - {var: "yarn.resourcemanager.scheduler.class", value: "{{ yarn_scheduler }}" }
  - {var: "yarn.resourcemanager.recovery.enabled", value: "{{ yarn_resourcemanager_recovery }}" }
  - {var: "yarn.resourcemanager.store.class", value: "{{ yarn_resourcemanager_store_class }}" }
  - {var: "yarn.resourcemanager.fs.state-store.uri", value: "{{ yarn_resourcemanager_store_uri }}" }
  - {var: "yarn.scheduler.minimum-allocation-mb", value: "{{ yarn_container_min_mb }}" }
  - {var: "yarn.scheduler.maximum-allocation-mb", value: "{{ yarn_container_max_mb }}" }
  - {var: "yarn.scheduler.maximum-allocation-vcores", value: "{{ yarn_container_max_cores }}" }
  - {var: "yarn.resourcemanager.bind-host", value: "{{ groups['resourcemanager'][0].split('.')[0] }}-{{ hadoop_cluster_name }}" }
  - {var: "yarn.web-proxy.address", value: "{{ groups['yarn_edge'][0].split('.')[0] }}-{{ hadoop_cluster_name }}:{{ yarn_webproxy_port }}" }
  notify: restart yarn
- name: update capacity-scheduler.xml for resouerce manager
  tags: [configure_yarn, upgrade]
  command: "/tmp/xmlpresent.sh --container-xpath \"/configuration\" --node \"property\" --property-node name --property-text \"{{ item.var  }}\" --value-node value --value \"{{ item.value  }}\" --file {{ hadoop_conf_dir }}/capacity-scheduler.xml"
  register: out
  changed_when: not out.stdout.startswith('NO-CHANGE')
  with_items:
  - {var: "yarn.scheduler.capacity.resource-calculator", value: "{{ yarn_scheduler_capacity_calculator }}" }
  notify: restart yarn
- name: update yarn-site.xml on node managers
  tags: [configure_yarn, upgrade, scale]
  command: "/tmp/xmlpresent.sh --container-xpath \"/configuration\" --node \"property\" --property-node name --property-text \"{{ item.var  }}\" --value-node value --value \"{{ item.value  }}\" --file {{ hadoop_conf_dir }}/yarn-site.xml"
  register: out
  changed_when: not out.stdout.startswith('NO-CHANGE')
  with_items:
  - {var: "yarn.nodemanager.local-dirs", value: "{{ yarn_nodemanager_local_dirs  }}" }
  - {var: "yarn.nodemanager.log-dirs", value: "{{ yarn_log_dir }}" }
  - {var: "yarn.nodemanager.log.retain-seconds", value: "{{ yarn_nodemanager_log_seconds }}" }
  - {var: "yarn.nodemanager.remote-app-log-dir", value: "{{ yarn_nodemanager_remote_log_dir }}" }
  - {var: "yarn.nodemanager.remote-app-log-dir-suffix", value: "{{ yarn_nodemanager_remote_log_dir_suffix  }}" }
  - {var: "yarn.nodemanager.resource.detect-hardware-capabilities", value: "{{ yarn_nodemanager_detect_hardware }}" }
  - {var: "yarn.nodemanager.resource.memory-mb", value: "{{ yarn_nodemanager_memory_mb  }}" }
  - {var: "yarn.nodemanager.resource.system-reserved-memory-mb", value: "{{ yarn_nodemanager_system_reserved_memory_mb  }}" }
  - {var: "yarn.nodemanager.resource.cpu-vcores", value: "{{ yarn_nodemanager_resource_vcores  }}" }
  - {var: "yarn.nodemanager.resource.count-logical-processors-as-cores", value: "{{ yarn_nodemanager_logical_procs_as_cores }}" }
  - {var: "yarn.nodemanager.resource.pcores-vcores-multiplier", value: "{{ yarn_nodemanager_resource_pcores_multiplier }}" }
  - {var: "yarn.nodemanager.vmem-check-enabled", value: "{{ yarn_nodemanager_check_vmem }}" }
  - {var: "yarn.nodemanager.pmem-check-enabled", value: "{{ yarn_nodemanager_check_pmem }}" }
  - {var: "yarn.nodemanager.vmem-pmem-ratio", value: "{{ yarn_nodemanager_vmem_pmem_ratio  }}" }
  - {var: "yarn.nodemanager.hostname", value: "{{ inventory_hostname.split('.')[0] }}-{{ hadoop_cluster_name }}" }
  - {var: "yarn.nodemanager.bind-host", value: "{{ inventory_hostname.split('.')[0] }}-{{ hadoop_cluster_name }}" }
  - {var: "yarn.nodemanager.aux-services", value: "spark_shuffle" }
  - {var: "yarn.nodemanager.aux-services.spark_shuffle.class", value: "org.apache.spark.network.yarn.YarnShuffleService" }
  notify: restart yarn
- name: copy conf file xml files if template not exists use aready existing
  tags: [configure_map_reduce, upgrade]
  copy:
    src: "{{ hadoop_conf_dir }}/mapred-site.xml"
    dest: "{{ hadoop_conf_dir }}/mapred-site.xml.template"
    remote_src: True
    force: false
    owner: yarn
    group: hadoop
    mode: 0770
- name: copy conf file xml files
  tags: [configure_map_reduce, upgrade]
  copy:
    src: "{{ hadoop_conf_dir }}/mapred-site.xml.template"
    dest: "{{ hadoop_conf_dir }}/mapredsite.xml"
    remote_src: True
    force: false
    owner: yarn
    group: hadoop
    mode: 0770
- name: update mapred-site.xml on nodes
  tags: [configure_map_reduce, upgrade, scale]
  command: "/tmp/xmlpresent.sh --container-xpath \"/configuration\" --node \"property\" --property-node name --property-text \"{{ item.var  }}\" --value-node value --value \"{{ item.value  }}\" --file {{ hadoop_conf_dir }}/mapred-site.xml"
  register: out
  changed_when: not out.stdout.startswith('NO-CHANGE')
  with_items:
  - {var: "mapreduce.framework.name", value: "{{ mapreduce_framework_name }}" }
  - {var: "mapreduce.map.memory.mb", value: "{{ ((1.5*available_memory_mb|int) / (node_cpu.stdout|int))|int }}" }
  - {var: "mapreduce.map.java.opts", value: "-Xmx{{ (available_memory_mb|int / node_cpu.stdout|int)|int }}M" }
  - {var: "mapreduce.reduce.memory.mb", value: "{{ ((2*available_memory_mb|int) / (node_cpu.stdout|int))|int }}" }
  - {var: "mapreduce.reduce.java.opts", value: "-Xmx{{ (2*available_memory_mb|int / node_cpu.stdout|int)|int }}M" }
  - {var: "mapreduce.task.io.sort.mb", value: "{{ ((0.5*available_memory_mb|int) / (node_cpu.stdout|int))|int }}" }
  - {var: "mapreduce.task.io.sort.factor", value: "{{ mapreduce_task_io_sort_factor  }}" }
  - {var: "mapreduce.reduce.shuffle.parallelcopies", value: "{{ mapreduce_reduce_shuffle_parallelcopies  }}" }
  - {var: "mapreduce.jobhistory.address", value: "{{ groups['resourcemanager'][0].split('.')[0]}}:{{mapreduce_jobhistory_port  }}" }
  - {var: "mapreduce.jobhistory.webapp.address", value: "{{ groups['resourcemanager'][0].split('.')[0]}}:{{ mapreduce_jobhistory_webapp_port }}" }
  - {var: "mapreduce.jobhistory.intermediate-done-dir", value: "{{ mapreduce_jobhistory_intermediate_done_dir  }}" }
  - {var: "mapreduce.jobhistory.done-dir", value: "{{ mapreduce_jobhistory_done_dir  }}" }
